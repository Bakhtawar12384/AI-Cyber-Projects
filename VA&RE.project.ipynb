{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb26693-bffa-4694-bcd9-f3bbc2c2ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA COLLECTION PART 1 :1. Data Source : NVD (https://nvd.nist.gov/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88577e5-4107-4b77-a1a7-46d2cf04480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting search : general ===\n",
      "Collected 1966 new CVEs (Total: 1966)\n",
      "Collected 1997 new CVEs (Total: 3963)\n",
      "Collected 1992 new CVEs (Total: 5955)\n",
      "Collected 1972 new CVEs (Total: 7927)\n",
      "Collected 1976 new CVEs (Total: 9903)\n",
      "Collected 1978 new CVEs (Total: 11881)\n",
      "Collected 1965 new CVEs (Total: 13846)\n",
      "Collected 1971 new CVEs (Total: 15817)\n",
      "Collected 1974 new CVEs (Total: 17791)\n",
      "Collected 1990 new CVEs (Total: 19781)\n",
      "Collected 1990 new CVEs (Total: 21771)\n",
      "\n",
      "=== Starting search : network OR protocol OR remote OR http OR tls OR api ===\n",
      "No more vulnerabilities\n",
      "\n",
      "=== Starting search : os OR kernel OR local OR privilege OR memory OR driver ===\n",
      "No more vulnerabilities\n",
      "\n",
      "=== Starting search : vulnerability OR exploit OR attack OR security ===\n",
      "Collected 1039 new CVEs (Total: 22810)\n",
      "\n",
      "Saving 22727 CVEs to cve_dataset.csv\n",
      "Data collection completed. Below are Dataset statistics:\n",
      "- Total entries collected : 22727\n",
      "- OS vulnerabilities collected : 15876\n",
      "- Network vulnerabilities collected : 6851\n",
      "- Average CVSS score is : 6.10\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "NVD_API_URL = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "NVD_API_KEY = os.getenv(\"NVD_API_KEY\", None)\n",
    "RESULTS_PER_PAGE = 2000  \n",
    "MAX_RESULTS = 20000      # Target to collect \n",
    "OUTPUT_CSV_FILE = \"cve_dataset.csv\"\n",
    "REQUEST_DELAY_SECONDS = 6 if not NVD_API_KEY else 0.6\n",
    "MAX_RETRIES = 5           \n",
    "RETRY_BACKOFF_FACTOR = 2  \n",
    "\n",
    "OS_KEYWORDS = [\n",
    "    'linux', 'kernel', 'windows', 'macos', 'android', 'driver',\n",
    "    'privilege escalation', 'root access', 'memory corruption',\n",
    "    'buffer overflow', 'system call', 'filesystem', 'registry',\n",
    "    'local execution', 'sudo', 'sandbox escape', 'dll hijacking',\n",
    "    'service permissions', 'race condition', 'symlink', 'inode',\n",
    "    'scheduler', 'interrupt handler', 'page fault', 'kernel panic',\n",
    "    'blue screen', 'bsod', 'ring0', 'hypervisor', 'ioctl', 'syscall'\n",
    "]\n",
    "\n",
    "NETWORK_KEYWORDS = [\n",
    "    'http', 'https', 'tcp', 'udp', 'dns', 'firewall', 'router',\n",
    "    'remote code execution', 'sql injection', 'xss', 'csrf',\n",
    "    'ssrf', 'vpn', 'ssl', 'tls', 'api', 'rest', 'soap', 'oauth',\n",
    "    'jwt', 'websocket', 'ddos', 'amplification', 'port scanning',\n",
    "    'man-in-the-middle', 'packet injection', 'arp spoofing',\n",
    "    'dns spoofing', 'http request smuggling', 'cache poisoning',\n",
    "    'tls handshake', 'certificate validation', 'session hijacking',\n",
    "    'credential stuffing', 'api endpoint', 'zero-day', 'wormable'\n",
    "]\n",
    "\n",
    "# --- API Functions ---\n",
    "def fetch_nvd_data(start_index=0, keyword_filter=None):\n",
    "    \"\"\"Fetch CVE data from NVD API with retry logic\"\"\"\n",
    "    headers = {'apiKey': NVD_API_KEY} if NVD_API_KEY else {}\n",
    "    params = {\n",
    "        'resultsPerPage': RESULTS_PER_PAGE,\n",
    "        'startIndex': start_index\n",
    "    }\n",
    "    \n",
    "    if keyword_filter:\n",
    "        params['keywordSearch'] = keyword_filter\n",
    "\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(NVD_API_URL, headers=headers, \n",
    "                                 params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                wait = (RETRY_BACKOFF_FACTOR ** attempt) * 30\n",
    "                print(f\"Rate limited. Retrying in {wait}s...\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            print(f\"HTTP Error: {e}\")\n",
    "            return None\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {str(e)}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep((RETRY_BACKOFF_FACTOR ** attempt) * 10)\n",
    "                continue\n",
    "            return None\n",
    "\n",
    "# --- Data Processing ---\n",
    "def get_cvss_data(cve_item):\n",
    "    \"\"\"Extract CVSS data with version prioritization\"\"\"\n",
    "    metrics = cve_item.get('metrics', {})\n",
    "    \n",
    "    # Try CVSS v3.1 first\n",
    "    if 'cvssMetricV31' in metrics:\n",
    "        cvss_data = metrics['cvssMetricV31'][0].get('cvssData', {})\n",
    "        return (\n",
    "            cvss_data.get('baseScore'),\n",
    "            cvss_data.get('vectorString'),\n",
    "            cvss_data.get('baseSeverity', '').upper()\n",
    "        )\n",
    "    \n",
    "    # Fallback to CVSS v3.0\n",
    "    if 'cvssMetricV30' in metrics:\n",
    "        cvss_data = metrics['cvssMetricV30'][0].get('cvssData', {})\n",
    "        return (\n",
    "            cvss_data.get('baseScore'),\n",
    "            cvss_data.get('vectorString'),\n",
    "            cvss_data.get('baseSeverity', '').upper()\n",
    "        )\n",
    "    \n",
    "    # Fallback to CVSS v2\n",
    "    if 'cvssMetricV2' in metrics:\n",
    "        cvss_data = metrics['cvssMetricV2'][0].get('cvssData', {})\n",
    "        score = cvss_data.get('baseScore')\n",
    "        severity = \"LOW\"\n",
    "        if score >= 7.0:\n",
    "            severity = \"HIGH\"\n",
    "        elif score >= 4.0:\n",
    "            severity = \"MEDIUM\"\n",
    "        return (\n",
    "            score,\n",
    "            cvss_data.get('vectorString'),\n",
    "            severity\n",
    "        )\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "def determine_layer(description):\n",
    "    \"\"\"Classify vulnerability layer with priority to network keywords\"\"\"\n",
    "    desc = description.lower()\n",
    "    os_count = sum(1 for kw in OS_KEYWORDS if re.search(r'\\b' + re.escape(kw) + r'\\b', desc))\n",
    "    net_count = sum(1 for kw in NETWORK_KEYWORDS if re.search(r'\\b' + re.escape(kw) + r'\\b', desc))\n",
    "    \n",
    "    # Heuristic rules\n",
    "    if net_count > 0 and (net_count >= os_count or 'remote' in desc):\n",
    "        return \"Network\"\n",
    "    if os_count > 0 and ('local' in desc or 'privilege' in desc):\n",
    "        return \"OS\"\n",
    "    if net_count > 0:\n",
    "        return \"Network\"\n",
    "    return \"OS\"  # Default to OS if no keywords found\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Normalizing text for NLP processing\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'[^\\w\\s-]', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)       \n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collected_data = []\n",
    "    search_strategies = [\n",
    "        None,\n",
    "        \"network OR protocol OR remote OR http OR tls OR api\",\n",
    "        \"os OR kernel OR local OR privilege OR memory OR driver\",\n",
    "        \"vulnerability OR exploit OR attack OR security\"\n",
    "    ]\n",
    "\n",
    "    total_collected = 0\n",
    "    unique_cves = set()\n",
    "\n",
    "    for strategy in search_strategies:\n",
    "        start_index = 0\n",
    "        strategy_name = strategy or \"general\"\n",
    "        print(f\"\\n=== Starting search : {strategy_name} ===\")\n",
    "\n",
    "        while True:\n",
    "            data = fetch_nvd_data(start_index, strategy)\n",
    "            if not data:\n",
    "                print(\"Failed to fetch data!\")\n",
    "                break\n",
    "\n",
    "            vulnerabilities = data.get('vulnerabilities', [])\n",
    "            if not vulnerabilities:\n",
    "                print(\"No more vulnerabilities!!\")\n",
    "                break\n",
    "\n",
    "            current_count = 0\n",
    "            for item in vulnerabilities:\n",
    "                cve = item.get('cve', {})\n",
    "                cve_id = cve.get('id')\n",
    "                \n",
    "                \n",
    "                if cve_id in unique_cves:\n",
    "                    continue\n",
    "                unique_cves.add(cve_id)\n",
    "\n",
    "               \n",
    "                description = next((d['value'] for d in cve.get('descriptions', [])\n",
    "                                  if d.get('lang') == 'en'), '')\n",
    "                if not description:\n",
    "                    continue\n",
    "\n",
    "               \n",
    "                cvss_score, cvss_vector, severity = get_cvss_data(cve)\n",
    "                if cvss_score is None:\n",
    "                    continue\n",
    "\n",
    "               \n",
    "                clean_desc = clean_text(description)\n",
    "                layer = determine_layer(clean_desc)\n",
    "\n",
    "                collected_data.append({\n",
    "                    'CVE_ID': cve_id,\n",
    "                    'Description': clean_desc,\n",
    "                    'CVSS_Score': cvss_score,\n",
    "                    'CVSS_Vector': cvss_vector,\n",
    "                    'Severity': severity,\n",
    "                    'Layer': layer\n",
    "                })\n",
    "                current_count += 1\n",
    "\n",
    "            total_collected += current_count\n",
    "            print(f\"Collected {current_count} new CVEs (Total: {total_collected})\")\n",
    "\n",
    "            # Pagination control\n",
    "            start_index += RESULTS_PER_PAGE\n",
    "            if start_index >= data.get('totalResults', 0) or total_collected >= MAX_RESULTS:\n",
    "                break\n",
    "\n",
    "            time.sleep(REQUEST_DELAY_SECONDS)\n",
    "\n",
    "   \n",
    "    final_data = []\n",
    "    seen = set()\n",
    "    for item in collected_data:\n",
    "       \n",
    "        if (item['CVE_ID'] not in seen and \n",
    "            item['CVSS_Score'] is not None and \n",
    "            len(item['Description']) >= 50):\n",
    "            final_data.append(item)\n",
    "            seen.add(item['CVE_ID'])\n",
    "\n",
    "   \n",
    "    print(f\"\\nSaving {len(final_data)} CVEs to {OUTPUT_CSV_FILE}\")\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\n",
    "            'CVE_ID', 'Description', 'CVSS_Score', \n",
    "            'CVSS_Vector', 'Severity', 'Layer'\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(final_data)\n",
    "\n",
    "    print(\"Data collection completed. Below are Dataset statistics:\")\n",
    "    print(f\"- Total entries collected : {len(final_data)}\")\n",
    "    print(f\"- OS vulnerabilities collected : {sum(1 for x in final_data if x['Layer'] == 'OS')}\")\n",
    "    print(f\"- Network vulnerabilities collected : {sum(1 for x in final_data if x['Layer'] == 'Network')}\")\n",
    "    cvss_scores = [x['CVSS_Score'] for x in final_data]\n",
    "    print(f\"- Average CVSS score is : {sum(cvss_scores)/len(cvss_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2707c73-9096-48dd-b812-74c0271af5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e6d920-2571-4ba0-adf6-0d17b1122525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cve_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f87ce1e-f3cb-4331-b641-7d0d2268f920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>CVSS_Score</th>\n",
       "      <th>CVSS_Vector</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-1999-0095</td>\n",
       "      <td>the debug command in sendmail is enabled allow...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>AV:N/AC:L/Au:N/C:C/I:C/A:C</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-1999-1471</td>\n",
       "      <td>buffer overflow in passwd in bsd based operati...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>AV:L/AC:L/Au:N/C:C/I:C/A:C</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-1999-1122</td>\n",
       "      <td>vulnerability in restore in sunos 4 0 3 and ea...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>AV:L/AC:L/Au:N/C:P/I:P/A:P</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVE-1999-1467</td>\n",
       "      <td>vulnerability in rcp on sunos 4 0 x allows rem...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>AV:N/AC:L/Au:N/C:C/I:C/A:C</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVE-1999-1506</td>\n",
       "      <td>vulnerability in smi sendmail 4 0 and earlier ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>AV:N/AC:L/Au:N/C:P/I:P/A:P</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CVE_ID                                        Description  \\\n",
       "0  CVE-1999-0095  the debug command in sendmail is enabled allow...   \n",
       "1  CVE-1999-1471  buffer overflow in passwd in bsd based operati...   \n",
       "2  CVE-1999-1122  vulnerability in restore in sunos 4 0 3 and ea...   \n",
       "3  CVE-1999-1467  vulnerability in rcp on sunos 4 0 x allows rem...   \n",
       "4  CVE-1999-1506  vulnerability in smi sendmail 4 0 and earlier ...   \n",
       "\n",
       "   CVSS_Score                 CVSS_Vector Severity Layer  \n",
       "0        10.0  AV:N/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
       "1         7.2  AV:L/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
       "2         4.6  AV:L/AC:L/Au:N/C:P/I:P/A:P   MEDIUM    OS  \n",
       "3        10.0  AV:N/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
       "4         7.5  AV:N/AC:L/Au:N/C:P/I:P/A:P     HIGH    OS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae9e325-3516-4161-a7d6-306c6eac8c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (22727, 6)\n",
      "          CVE_ID                                        Description  \\\n",
      "0  CVE-1999-0095  the debug command in sendmail is enabled allow...   \n",
      "1  CVE-1999-1471  buffer overflow in passwd in bsd based operati...   \n",
      "2  CVE-1999-1122  vulnerability in restore in sunos 4 0 3 and ea...   \n",
      "3  CVE-1999-1467  vulnerability in rcp on sunos 4 0 x allows rem...   \n",
      "4  CVE-1999-1506  vulnerability in smi sendmail 4 0 and earlier ...   \n",
      "\n",
      "   CVSS_Score                 CVSS_Vector Severity Layer  \n",
      "0        10.0  AV:N/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
      "1         7.2  AV:L/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
      "2         4.6  AV:L/AC:L/Au:N/C:P/I:P/A:P   MEDIUM    OS  \n",
      "3        10.0  AV:N/AC:L/Au:N/C:C/I:C/A:C     HIGH    OS  \n",
      "4         7.5  AV:N/AC:L/Au:N/C:P/I:P/A:P     HIGH    OS  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Input data shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99f5425-0621-4d3f-9c21-07fc7e6af11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing Part 2: Data Preprocessing and Embedding Generation ===\n",
      "Using device: cpu\n",
      "Output directory: C:\\Windows\\system32\\Untitled Folder\\output\n",
      "Memory usage: 559.96 MB\n",
      "\n",
      "Searching for CSV files...\n",
      "Using input file: cve_dataset.csv\n",
      "\n",
      "Loading BERT tokenizer and model...\n",
      "BERT model loaded successfully!\n",
      "Memory usage: 563.08 MB\n",
      "\n",
      "Loading dataset...\n",
      "Successfully loaded 22727 records\n",
      "\n",
      "Data sample:\n",
      "          CVE_ID                                        Description Severity\n",
      "0  CVE-1999-0095  the debug command in sendmail is enabled allow...     HIGH\n",
      "1  CVE-1999-1471  buffer overflow in passwd in bsd based operati...     HIGH\n",
      "\n",
      "=== Starting Enhanced Preprocessing ===\n",
      "Memory usage: 565.51 MB\n",
      "\n",
      "[1/3] Extracting CVSS vector components...\n",
      "→ Extracted 10 components: ['AV', 'AC', 'Au', 'C', 'I', 'A', 'CVSS', 'PR', 'UI', 'S']\n",
      "\n",
      "[2/3] Applying label encoding to categorical features...\n",
      "→ Encoding AV... Done (unique values: 4)\n",
      "→ Encoding AC... Done (unique values: 3)\n",
      "→ Encoding PR... Done (unique values: 3)\n",
      "→ Encoding UI... Done (unique values: 2)\n",
      "→ Encoding S... Done (unique values: 2)\n",
      "→ Encoding C... Done (unique values: 5)\n",
      "→ Encoding I... Done (unique values: 5)\n",
      "→ Encoding A... Done (unique values: 5)\n",
      "\n",
      "[3/3] Applying standard scaling to CVSS scores...\n",
      "→ Scaling complete\n",
      "\n",
      "Preprocessing completed successfully!\n",
      "Memory usage: 579.48 MB\n",
      "\n",
      "Starting embedding generation...\n",
      "\n",
      "Generating BERT embeddings for 22727 descriptions...\n",
      "Processing batch 2841/2841...\n",
      "Embedding generation complete!\n",
      "Memory usage: 1052.43 MB\n",
      "\n",
      "Generated embeddings shape: (22727, 768)\n",
      "\n",
      "Creating UMAP visualization...\n",
      "Visualization saved to: C:\\Windows\\system32\\Untitled Folder\\output\\severity_plot.png\n",
      "\n",
      "Saving results...\n",
      "\n",
      "Successfully saved:\n",
      "- processed_data: C:\\Windows\\system32\\Untitled Folder\\output\\processed_cve_data.csv\n",
      "- embeddings: C:\\Windows\\system32\\Untitled Folder\\output\\cve_embeddings.npy\n",
      "- umap_coords: C:\\Windows\\system32\\Untitled Folder\\output\\umap_coordinates.csv\n",
      "Memory usage: 1546.94 MB\n",
      "\n",
      "=== Processing complete! ===\n"
     ]
    }
   ],
   "source": [
    "# PART 2 - Data Preprocessing and Embedding Generation \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import umap\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.use('TkAgg')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Constants\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / \"output\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBEDDING_MODEL = 'bert-base-uncased'\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "# Helper Functions\n",
    "def print_memory_usage():\n",
    "    print(f\"Memory usage: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "def get_latest_csv():\n",
    "    \"\"\"Find the most recent CSV file in the directory\"\"\"\n",
    "    csv_files = list(NOTEBOOK_DIR.glob('*.csv'))\n",
    "    if not csv_files:\n",
    "        return None\n",
    "    # Get file with latest modification time\n",
    "    latest = max(csv_files, key=lambda f: f.stat().st_mtime)\n",
    "    return latest.name\n",
    "\n",
    "def extract_cvss_components(vector_string):\n",
    "    if pd.isna(vector_string):\n",
    "        return {}\n",
    "    return {part.split(':')[0]: part.split(':')[1] \n",
    "            for part in vector_string.split('/') if ':' in part}\n",
    "\n",
    "def enhanced_preprocessing(df):\n",
    "    print(\"\\n=== Starting Enhanced Preprocessing ===\")\n",
    "    print_memory_usage()\n",
    "    \n",
    "    # 1. Extract CVSS components\n",
    "    print(\"\\n[1/3] Extracting CVSS vector components...\")\n",
    "    cvss_df = pd.json_normalize(df['CVSS_Vector'].apply(extract_cvss_components))\n",
    "    print(f\"→ Extracted {len(cvss_df.columns)} components: {list(cvss_df.columns)}\")\n",
    "    \n",
    "    for col in cvss_df.columns:\n",
    "        df[col] = cvss_df[col].fillna(cvss_df[col].mode()[0])\n",
    "    \n",
    "    # 2. Label Encoding\n",
    "    print(\"\\n[2/3] Applying label encoding to categorical features...\")\n",
    "    cvss_components = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
    "    for col in cvss_components:\n",
    "        if col in df.columns:\n",
    "            print(f\"→ Encoding {col}...\", end=' ')\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])\n",
    "            print(f\"Done (unique values: {len(df[col].unique())})\")\n",
    "    \n",
    "    # 3. Standard Scaling\n",
    "    print(\"\\n[3/3] Applying standard scaling to CVSS scores...\")\n",
    "    df['CVSS_Score'] = StandardScaler().fit_transform(df[['CVSS_Score']])\n",
    "    print(\"→ Scaling complete\")\n",
    "    \n",
    "    print(\"\\nPreprocessing completed successfully!\")\n",
    "    print_memory_usage()\n",
    "    return df\n",
    "\n",
    "def generate_bert_embeddings(texts, batch_size=BATCH_SIZE):\n",
    "    print(f\"\\nGenerating BERT embeddings for {len(texts)} descriptions...\")\n",
    "    embeddings = []\n",
    "    total_batches = (len(texts) // batch_size) + (1 if len(texts) % batch_size != 0 else 0)\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        print(f\"\\rProcessing batch {batch_num}/{total_batches}...\", end='', flush=True)\n",
    "        \n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    print(\"\\nEmbedding generation complete!\")\n",
    "    print_memory_usage()\n",
    "    return np.concatenate(embeddings)\n",
    "\n",
    "# Main \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Initializing Part 2: Data Preprocessing and Embedding Generation ===\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print_memory_usage()\n",
    "\n",
    "    # Auto-detect input file\n",
    "    print(\"\\nSearching for CSV files...\")\n",
    "    input_file = get_latest_csv()\n",
    "    if input_file is None:\n",
    "        raise FileNotFoundError(\"No CSV files found in the directory\")\n",
    "    \n",
    "    print(f\"Using input file: {input_file}\")\n",
    "    input_path = NOTEBOOK_DIR / input_file\n",
    "\n",
    "    # Load BERT model\n",
    "    print(\"\\nLoading BERT tokenizer and model...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained(EMBEDDING_MODEL)\n",
    "    model = BertModel.from_pretrained(EMBEDDING_MODEL).to(DEVICE)\n",
    "    model.eval()\n",
    "    print(\"BERT model loaded successfully!\")\n",
    "    print_memory_usage()\n",
    "\n",
    "    # Data Loading\n",
    "    try:\n",
    "        print(\"\\nLoading dataset...\")\n",
    "        df = pd.read_csv(input_path)\n",
    "        print(f\"Successfully loaded {len(df)} records\")\n",
    "        print(\"\\nData sample:\")\n",
    "        print(df[['CVE_ID', 'Description', 'Severity']].head(2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\nERROR: Failed to load data\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    # Preprocessing\n",
    "    required_cols = ['CVSS_Vector', 'Description', 'Severity']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        raise ValueError(f\"Input file missing required columns. Needed: {required_cols}\")\n",
    "    \n",
    "    if all(col in df.columns for col in ['AV', 'AC', 'PR', 'UI']):\n",
    "        print(\"\\nNote: Data appears to be already preprocessed\")\n",
    "        print(\"Skipping CVSS component extraction\")\n",
    "    else:\n",
    "        df = enhanced_preprocessing(df)\n",
    "\n",
    "    # Embedding Generation\n",
    "    print(\"\\nStarting embedding generation...\")\n",
    "    text_embeddings = generate_bert_embeddings(df['Description'].tolist())\n",
    "    print(f\"\\nGenerated embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "    # Visualization\n",
    "    print(\"\\nCreating UMAP visualization...\")\n",
    "    reducer = umap.UMAP(random_state=SEED)\n",
    "    embedding_2d = reducer.fit_transform(text_embeddings)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        x=embedding_2d[:, 0], y=embedding_2d[:, 1],\n",
    "        hue=df['Severity'],\n",
    "        palette={'CRITICAL': 'red', 'HIGH': 'orange', 'MEDIUM': 'yellow', 'LOW': 'green'},\n",
    "        alpha=0.6\n",
    "    )\n",
    "    plt.title(\"Vulnerability Embeddings by Severity\")\n",
    "    plt.tight_layout()\n",
    "    viz_path = OUTPUT_DIR / \"severity_plot.png\"\n",
    "    plt.savefig(viz_path)\n",
    "    print(f\"Visualization saved to: {viz_path}\")\n",
    "\n",
    "   \n",
    "    print(\"\\nSaving results...\")\n",
    "    try:\n",
    "        output_paths = {\n",
    "            'processed_data': OUTPUT_DIR / \"processed_cve_data.csv\",\n",
    "            'embeddings': OUTPUT_DIR / \"cve_embeddings.npy\",\n",
    "            'umap_coords': OUTPUT_DIR / \"umap_coordinates.csv\"\n",
    "        }\n",
    "        \n",
    "        df.to_csv(output_paths['processed_data'], index=False)\n",
    "        np.save(output_paths['embeddings'], text_embeddings.astype(np.float32))\n",
    "        pd.DataFrame(embedding_2d, columns=['umap_x', 'umap_y']).to_csv(\n",
    "            output_paths['umap_coords'], index=False)\n",
    "        \n",
    "        print(\"\\nSuccessfully saved:\")\n",
    "        for name, path in output_paths.items():\n",
    "            print(f\"- {name}: {path}\")\n",
    "        print_memory_usage()\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving files: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    print(\"\\n=== Processing complete! ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb49d89f-9496-498c-a0c7-05fb507a04b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " Part 3 Initialized: Vulnerability Severity Classification\n",
      "======================================================================\n",
      "Working directory: C:\\Windows\\system32\\Untitled Folder\n",
      "Output directory: C:\\Windows\\system32\\Untitled Folder\\output\n",
      "Models directory: C:\\Windows\\system32\\Untitled Folder\\output\\models\n",
      "\n",
      " Verifying required files exist...\n",
      " - processed_cve_data.csv:  Found\n",
      " - cve_embeddings.npy:  Found\n",
      " - cve_embeddings.csv:  Found\n",
      "\n",
      " Loading data...\n",
      "\n",
      " Data loaded in 0.15s\n",
      " Dataset shape: (22727, 16)\n",
      " Embeddings shape: (22727, 768)\n",
      "\n",
      " Data preview:\n",
      "          CVE_ID                                        Description Severity\n",
      "0  CVE-1999-0095  the debug command in sendmail is enabled allow...     HIGH\n",
      "1  CVE-1999-1471  buffer overflow in passwd in bsd based operati...     HIGH\n",
      "2  CVE-1999-1122  vulnerability in restore in sunos 4 0 3 and ea...   MEDIUM\n",
      "\n",
      " Preparing data for modeling...\n",
      "\n",
      "Final feature matrix shape: (18181, 777)\n",
      " Class distribution (training set):\n",
      "Severity\n",
      "MEDIUM      0.477311\n",
      "HIGH        0.431659\n",
      "LOW         0.084484\n",
      "CRITICAL    0.006545\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      " Training Logistic Regression\n",
      "==================================================\n",
      "\n",
      " Training time: 10.63s\n",
      " Test Accuracy: 0.9811\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CRITICAL       0.34      0.50      0.41        30\n",
      "        HIGH       0.99      0.98      0.98      1962\n",
      "         LOW       0.97      0.96      0.97       384\n",
      "      MEDIUM       0.99      0.99      0.99      2170\n",
      "\n",
      "    accuracy                           0.98      4546\n",
      "   macro avg       0.82      0.86      0.84      4546\n",
      "weighted avg       0.98      0.98      0.98      4546\n",
      "\n",
      "\n",
      "==================================================\n",
      " Training Random Forest\n",
      "==================================================\n",
      "\n",
      " Training time: 74.46s\n",
      " Test Accuracy: 0.9408\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CRITICAL       0.88      0.23      0.37        30\n",
      "        HIGH       0.96      0.94      0.95      1962\n",
      "         LOW       0.92      0.89      0.91       384\n",
      "      MEDIUM       0.93      0.96      0.94      2170\n",
      "\n",
      "    accuracy                           0.94      4546\n",
      "   macro avg       0.92      0.76      0.79      4546\n",
      "weighted avg       0.94      0.94      0.94      4546\n",
      "\n",
      "\n",
      " Saving models and scalers...\n",
      "\n",
      " Saved files:\n",
      " - C:\\Windows\\system32\\Untitled Folder\\output\\models\\vuln_severity_lr_model.joblib\n",
      " - C:\\Windows\\system32\\Untitled Folder\\output\\models\\vuln_severity_lr_scaler.joblib\n",
      " - C:\\Windows\\system32\\Untitled Folder\\output\\models\\vuln_severity_rf_model.joblib\n",
      " - C:\\Windows\\system32\\Untitled Folder\\output\\models\\vuln_severity_rf_scaler.joblib\n",
      "\n",
      "======================================================================\n",
      "PART 3 COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Part 3: (A) Vulnerability Severity Classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import dump  \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / \"output\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"  \n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" Part 3 Initialized: Vulnerability Severity Classification\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Working directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\\n\")\n",
    "\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Verifying required files exist...\")\n",
    "required_files = {\n",
    "    \"processed_cve_data.csv\": False,\n",
    "    \"cve_embeddings.npy\": False,\n",
    "    \"cve_embeddings.csv\": False\n",
    "}\n",
    "\n",
    "for file in required_files:\n",
    "    if (OUTPUT_DIR / file).exists():\n",
    "        required_files[file] = True\n",
    "    print(f\" - {file}: {' Found' if required_files[file] else ' Missing'}\")\n",
    "\n",
    "if not any([required_files[\"cve_embeddings.npy\"], required_files[\"cve_embeddings.csv\"]]):\n",
    "    raise FileNotFoundError(\"No embeddings file found (.npy or .csv)\")\n",
    "\n",
    "print(\"\\n Loading data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(OUTPUT_DIR / \"processed_cve_data.csv\")\n",
    "    \n",
    "    # Load embeddings (prefer .npy, fallback to .csv)\n",
    "    if required_files[\"cve_embeddings.npy\"]:\n",
    "        embeddings = np.load(OUTPUT_DIR / \"cve_embeddings.npy\")\n",
    "    else:\n",
    "        embeddings = pd.read_csv(OUTPUT_DIR / \"cve_embeddings.csv\").values\n",
    "    \n",
    "    print(f\"\\n Data loaded in {time.time()-start_time:.2f}s\")\n",
    "    print(f\" Dataset shape: {df.shape}\")\n",
    "    print(f\" Embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "    print(\"\\n Data preview:\")\n",
    "    print(df[['CVE_ID', 'Description', 'Severity']].head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"\\n Preparing data for modeling...\")\n",
    "\n",
    "cvss_features = ['CVSS_Score', 'AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
    "X = np.concatenate([embeddings, df[cvss_features].values], axis=1)\n",
    "y = df['Severity']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X_train.shape}\")\n",
    "print(\" Class distribution (training set):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# --- Model Training & Evaluation ---\n",
    "def train_evaluate_model(model, model_name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" Training {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n Training time: {train_time:.2f}s\")\n",
    "    print(f\" Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced' \n",
    ")\n",
    "lr = train_evaluate_model(lr, \"Logistic Regression\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "rf = train_evaluate_model(rf, \"Random Forest\")\n",
    "\n",
    "\n",
    "print(\"\\n Saving models and scalers...\")\n",
    "try:\n",
    "    \n",
    "    dump(lr, MODELS_DIR / 'vuln_severity_lr_model.joblib')\n",
    "    dump(scaler, MODELS_DIR / 'vuln_severity_lr_scaler.joblib')\n",
    "    \n",
    "    \n",
    "    dump(rf, MODELS_DIR / 'vuln_severity_rf_model.joblib')\n",
    "    dump(scaler, MODELS_DIR / 'vuln_severity_rf_scaler.joblib')\n",
    "    \n",
    "    print(\"\\n Saved files:\")\n",
    "    print(f\" - {MODELS_DIR / 'vuln_severity_lr_model.joblib'}\")\n",
    "    print(f\" - {MODELS_DIR / 'vuln_severity_lr_scaler.joblib'}\")\n",
    "    print(f\" - {MODELS_DIR / 'vuln_severity_rf_model.joblib'}\")\n",
    "    print(f\" - {MODELS_DIR / 'vuln_severity_rf_scaler.joblib'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n Error saving models: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19123462-84ba-4d1d-a805-7e2c4a96bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CVE Remediation Advisor ===\n",
      "Loading data...\n",
      "Testing API connection...\n",
      "API connection successful!\n",
      "\n",
      "Total CVEs available: 22727\n",
      "Sample data:\n",
      "          CVE_ID Severity\n",
      "0  CVE-1999-0095     HIGH\n",
      "1  CVE-1999-1471     HIGH\n",
      "2  CVE-1999-1122   MEDIUM\n",
      "\n",
      "=== Remediation for CVE-1999-0095 ===\n",
      "## Remediation for CVE-1999-0095 (sendmail debug command vulnerability)\n",
      "\n",
      "**Severity:** HIGH\n",
      "**CVSS:** (While a CVSS score is provided,  CVSS scoring wasn't standardized until much later.  This score likely isn't accurate or official.)\n",
      "\n",
      "**Description:**  This vulnerability allows remote attackers to execute arbitrary commands as root on a vulnerable sendmail server if the debug option is enabled.\n",
      "\n",
      "\n",
      "**1. Immediate Containment Measures:**\n",
      "\n",
      "* **Disable the debug option in sendmail immediately.**  This is the fastest way to mitigate the immediate threat.  This may involve:\n",
      "    * Editing the sendmail.cf configuration file and removing/commenting out any lines related to the debug option (e.g., `O DebugFlags=`).  The exact syntax depends on the sendmail version.\n",
      "    * Restarting the sendmail service for the changes to take effect.  The restart command also varies based on the operating system (e.g., `/etc/init.d/sendmail restart`, `systemctl restart sendmail`).\n",
      "* **Restrict network access to the sendmail server.**  If possible, limit connections to only trusted hosts and networks using firewall rules.  Block port 25 (SMTP) from untrusted sources.\n",
      "* **Monitor system logs for suspicious activity.**  Pay close attention to authentication logs, command history, and any unusual processes running as root.\n",
      "\n",
      "\n",
      "**2. Permanent Technical Fixes:**\n",
      "\n",
      "* **Upgrade to a patched version of sendmail.**  This is the most effective long-term solution. Consult the vendor's website (Sendmail, Inc.) for the latest security updates and upgrade instructions.  Be sure to test the upgrade in a non-production environment first.\n",
      "* **If upgrading is not immediately possible, ensure the debug option is definitively disabled and carefully review the entire sendmail configuration for other potential security weaknesses.** Consult the sendmail documentation for secure configuration practices.\n",
      "* **Consider replacing sendmail with a more modern and actively maintained mail transfer agent (MTA).** Postfix, Exim, and other MTAs offer enhanced security features and are often easier to configure securely.\n",
      "\n",
      "\n",
      "**3. Workarounds:**\n",
      "\n",
      "* **If disabling debug is impossible due to dependencies (unlikely but conceivable in legacy setups):** implement very strict firewall rules that only allow connections from absolutely essential hosts and networks. This significantly limits the attack surface.\n",
      "* **Use a chroot jail:** Running sendmail within a chroot environment can restrict the damage caused by a successful exploit, although this is a complex undertaking and doesn't address the core vulnerability. This is not a recommended primary fix.\n",
      "\n",
      "\n",
      "**4. Vendor Patch References:**\n",
      "\n",
      "* Specific patch information for this CVE is difficult to find due to its age.  The best approach is to contact Sendmail Inc. directly or refer to their older documentation archives if accessible.  Focus on upgrading to a much more recent sendmail version.\n",
      "\n",
      "\n",
      "**5. Detection Methods:**\n",
      "\n",
      "* **Review sendmail logs:** Examine the logs for any signs of unauthorized use of the debug command.\n",
      "* **Intrusion Detection/Prevention Systems (IDS/IPS):** Configure your IDS/IPS to detect attempts to exploit this vulnerability by monitoring SMTP traffic for debug commands.\n",
      "* **File Integrity Monitoring (FIM):** FIM tools can alert you to any unauthorized modifications to the sendmail configuration files.\n",
      "* **Vulnerability Scanners:** Regularly scan your systems with vulnerability scanners to identify known vulnerabilities, including outdated sendmail versions.\n",
      "* **Network traffic analysis:** Examine network traffic for unexpected connections to port 25 or unusual SMTP commands.\n",
      "\n",
      "\n",
      "**Important Note:**  Due to the age of this CVE, reliance on extremely old sendmail versions is strongly discouraged. Modern email servers have significantly improved security features.  Prioritize upgrading to a supported and actively maintained MTA.  If  you *must* run a very old version, isolate it as much as possible from the rest of your network.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1471 ===\n",
      "## Remediation for CVE-1999-1471 (Buffer Overflow in passwd)\n",
      "\n",
      "**Description:** A buffer overflow vulnerability exists in the `passwd` utility on BSD-based operating systems (versions 4.3 and earlier). Local users can exploit this vulnerability to gain root privileges by providing excessively long input for the shell or GECOS field.\n",
      "\n",
      "**Severity:** HIGH\n",
      "**CVSS:** 0.5648426389166081 (Note: This CVSS score appears unusually low for a root privilege escalation vulnerability.  Modern CVSS scoring would likely be much higher.)\n",
      "\n",
      "\n",
      "### 1. Immediate Containment Measures\n",
      "\n",
      "* **Restrict `passwd` usage:**  Immediately restrict direct usage of the `passwd` command for non-administrative users.  This can be achieved through:\n",
      "    * **sudoers file modification:** Remove the `passwd` command from the allowed commands in the `/etc/sudoers` file (or its equivalent) for all users except designated administrators.\n",
      "    * **Restricted shell:** Place affected users in a restricted shell environment that doesn't allow execution of `passwd`.\n",
      "* **Monitor for suspicious activity:**  Increase monitoring of system logs (especially authentication logs) for any unusual patterns or attempts to modify user information.\n",
      "* **Identify potentially compromised accounts:** Review user accounts for any recently modified shell or GECOS fields that are unusually long.\n",
      "\n",
      "\n",
      "### 2. Permanent Technical Fixes\n",
      "\n",
      "* **Upgrade the operating system:** The primary and most effective fix is to upgrade the affected BSD-based operating system to a version that includes a patch for this vulnerability (4.4 and later). This should be prioritized.\n",
      "* **Backport patches (if available):** If an upgrade is not immediately feasible, check if the vendor provides backported security patches for older releases. Apply these patches as soon as possible.\n",
      "* **Replace vulnerable `passwd` binary (if source code available):**  If patches are unavailable, and you have access to the source code of the `passwd` utility,  recompile the binary with improved input validation and buffer overflow protection.  This requires significant technical expertise and is a less desirable option compared to upgrading.\n",
      "\n",
      "\n",
      "### 3. Workarounds (Less effective, use with caution)\n",
      "\n",
      "* **Input length restriction (if possible):** If the affected system allows configuration of maximum input lengths for user information fields, consider implementing strict length limitations to prevent overflow.  This might not be feasible on all systems and is not a guaranteed solution.\n",
      "* **Alternative password management tools:** Explore the use of alternative password management tools that are not vulnerable to this specific exploit. However, this only mitigates the risk associated with `passwd` itself and doesn't address the underlying vulnerability.\n",
      "\n",
      "\n",
      "### 4. Vendor Patch References\n",
      "\n",
      "* **FreeBSD:**  Consult the FreeBSD security advisories and update releases for patches related to this vulnerability.  FreeBSD 4.4 and later should address this issue. Other BSD variants like NetBSD and OpenBSD would have their own advisories.  Check their respective security resources.\n",
      "* **Specific vendor:** Since the vulnerability is generic to BSD 4.3 and earlier, the specific patch will depend on the exact BSD distribution used. Contact the operating system vendor or consult their security advisories.\n",
      "\n",
      "### 5. Detection Methods\n",
      "\n",
      "* **Log Analysis:** Monitor authentication logs (`/var/log/auth.log` or similar) for failed `passwd` executions with unusually long input strings in the shell or GECOS fields.\n",
      "* **File Integrity Monitoring (FIM):** Implement FIM to detect unauthorized modifications to the `passwd` binary itself or related system files.\n",
      "* **Vulnerability Scanners:**  While this vulnerability is very old, some vulnerability scanners might still be able to detect vulnerable versions of BSD.\n",
      "* **Manual Inspection of User Accounts:** Periodically review user account information (e.g., using `/etc/passwd` or system administration tools) to identify suspiciously long shell or GECOS field entries.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**Important Note:** Due to the age of this vulnerability, information might be limited. Contacting the vendor of the specific BSD distribution used is crucial for obtaining accurate and relevant remediation advice.  Upgrading to a supported, patched operating system is strongly recommended. \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1122 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1467 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1506 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-0084 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-2000-0388 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-0209 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1198 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1391 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1392 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1057 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1554 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1197 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1115 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1258 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1438 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1211 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1212 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1194 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1193 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1123 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1034 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1415 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1090 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-0498 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1468 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-0167 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1493 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Remediation for CVE-1999-1032 ===\n",
      "API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Stopping after processing 30 CVEs\n",
      "\n",
      "Processing complete! Analyzed 30 CVEs\n"
     ]
    }
   ],
   "source": [
    "# PART 3 : (B) Remediation Suggestion System\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / \"output\"\n",
    "\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyC5l0zamvs5CpxjLOFD7htJDWVloFYBYrs\") \n",
    "\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')  \n",
    "\n",
    "def get_remediation(cve_data):\n",
    "    \"\"\"Remediation generator with error handling\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    As a cybersecurity analyst, provide detailed remediation for:\n",
    "    \n",
    "    CVE ID: {cve_data['CVE_ID']}\n",
    "    Description: {cve_data['Description']}\n",
    "    Severity: {cve_data['Severity']}\n",
    "    CVSS: {cve_data['CVSS_Score']}\n",
    "    \n",
    "    Include:\n",
    "    1. Immediate containment measures\n",
    "    2. Permanent technical fixes\n",
    "    3. Workarounds \n",
    "    4. Vendor patch references\n",
    "    5. Detection methods\n",
    "    \n",
    "    Format with clear headers and bullet points.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"API Error: {str(e)}\"\n",
    "\n",
    "def load_cve_data():\n",
    "    \"\"\"Load and validate data\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(OUTPUT_DIR / \"processed_cve_data.csv\")\n",
    "        required_cols = ['CVE_ID', 'Description', 'Severity', 'CVSS_Score']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"Error: Missing required columns. Needed: {required_cols}\")\n",
    "            return None\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Data loading failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== CVE Remediation Advisor ===\")\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Verify API connection\n",
    "    try:\n",
    "        print(\"Testing API connection...\")\n",
    "        test_response = model.generate_content(\"Hello\")\n",
    "        print(\"API connection successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"API Connection Error: {str(e)}\")\n",
    "        print(\"Available models:\", [m.name for m in genai.list_models()])\n",
    "        exit()\n",
    "    \n",
    "    df = load_cve_data()\n",
    "    if df is not None:\n",
    "        print(f\"\\nTotal CVEs available: {len(df)}\")\n",
    "        print(\"Sample data:\")\n",
    "        print(df[['CVE_ID', 'Severity']].head(3))\n",
    "        \n",
    "        # Process with limit \n",
    "        max_cves = 30\n",
    "        processed_count = 0\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            if processed_count >= max_cves:\n",
    "                print(f\"\\nStopping after processing {max_cves} CVEs\")\n",
    "                break\n",
    "                \n",
    "            print(f\"\\n=== Remediation for {row['CVE_ID']} ===\")\n",
    "            remediation = get_remediation(row)\n",
    "            print(remediation)\n",
    "            print(\"-\" * 50)\n",
    "            processed_count += 1\n",
    "        \n",
    "        print(f\"\\nProcessing complete! Analyzed {processed_count} CVEs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e06407cd-9b96-4331-bf07-2434bb5be3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " Part 4: System Evaluation Metrics\n",
      "======================================================================\n",
      "Evaluation results will be saved to: C:\\Windows\\system32\\Untitled Folder\\output\\evaluation\n",
      "\n",
      "Starting evaluation process...\n",
      "\n",
      "==================================================\n",
      " Evaluating Classification Models\n",
      "==================================================\n",
      "\n",
      "Loading and preparing data...\n",
      "- Loaded 22727 records from processed_cve_data.csv\n",
      "- Loaded embeddings with shape: (22727, 768)\n",
      "\n",
      "Loading trained models...\n",
      "\n",
      "Running predictions...\n",
      "\n",
      "Classification Metrics:\n",
      "                     Accuracy  Precision  Recall     F1\n",
      "Logistic Regression    0.9811     0.9831  0.9811 0.9820\n",
      "Random Forest          0.9408     0.9407  0.9408 0.9394\n",
      "\n",
      "Generating confusion matrices...\n",
      "- Saved confusion_matrices.png\n",
      "\n",
      "==================================================\n",
      " Evaluating Remediation Generation Quality\n",
      "==================================================\n",
      "\n",
      "Loading 20 samples for evaluation...\n",
      "Loading NLP evaluation models...\n",
      "\n",
      "Evaluating samples:\n",
      "- Sample 1/20: CVE-2004-0984\n",
      "- Sample 2/20: CVE-2006-6060\n",
      "- Sample 3/20: CVE-2004-0512\n",
      "- Sample 4/20: CVE-2006-1581\n",
      "- Sample 5/20: CVE-2002-2323\n",
      "- Sample 6/20: CVE-2005-3812\n",
      "- Sample 7/20: CVE-2001-0065\n",
      "- Sample 8/20: CVE-2017-12237\n",
      "- Sample 9/20: CVE-2000-0085\n",
      "- Sample 10/20: CVE-2006-4233\n",
      "- Sample 11/20: CVE-2003-0546\n",
      "- Sample 12/20: CVE-2006-2432\n",
      "- Sample 13/20: CVE-2006-4450\n",
      "- Sample 14/20: CVE-2005-4449\n",
      "- Sample 15/20: CVE-2005-2216\n",
      "- Sample 16/20: CVE-2002-0456\n",
      "- Sample 17/20: CVE-2004-0766\n",
      "- Sample 18/20: CVE-2006-1197\n",
      "- Sample 19/20: CVE-2006-0956\n",
      "- Sample 20/20: CVE-2000-0423\n",
      "\n",
      "Generation Metrics:\n",
      "              BLEU: 0.4237\n",
      "           ROUGE-L: 0.6222\n",
      "Semantic Similarity: 0.9556\n",
      "\n",
      "Saved generation_metrics.png\n",
      "\n",
      "======================================================================\n",
      " EVALUATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Summary of saved files:\n",
      "- Classification metrics: C:\\Windows\\system32\\Untitled Folder\\output\\evaluation\\classification_metrics.csv\n",
      "- Generation metrics:    C:\\Windows\\system32\\Untitled Folder\\output\\evaluation\\generation_metrics.csv\n",
      "- Confusion matrices:    C:\\Windows\\system32\\Untitled Folder\\output\\evaluation\\confusion_matrices.png\n",
      "- Generation plot:       C:\\Windows\\system32\\Untitled Folder\\output\\evaluation\\generation_metrics.png\n"
     ]
    }
   ],
   "source": [
    "# PART 4: System Evaluation Metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "from joblib import load\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / \"output\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "EVAL_DIR = OUTPUT_DIR / \"evaluation\"\n",
    "EVAL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" Part 4: System Evaluation Metrics\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Evaluation results will be saved to: {EVAL_DIR}\")\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load and prepare data ensuring consistent feature dimensions\"\"\"\n",
    "    print(\"\\nLoading and preparing data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(OUTPUT_DIR / \"processed_cve_data.csv\")\n",
    "    print(f\"- Loaded {len(df)} records from processed_cve_data.csv\")\n",
    "    \n",
    "    # Load embeddings\n",
    "    embeddings = np.load(OUTPUT_DIR / \"cve_embeddings.npy\")\n",
    "    print(f\"- Loaded embeddings with shape: {embeddings.shape}\")\n",
    "    \n",
    "    if embeddings.shape[1] > 768:\n",
    "        embeddings = embeddings[:, :768]\n",
    "        print(\"- Trimmed embeddings to 768 dimensions\")\n",
    "    \n",
    "    # Prepare features\n",
    "    cvss_features = ['CVSS_Score', 'AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
    "    missing = [col for col in cvss_features if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required CVSS features: {missing}\")\n",
    "    \n",
    "    X = np.concatenate([embeddings, df[cvss_features].values], axis=1)\n",
    "    y = df['Severity']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def evaluate_classification_models():\n",
    "    \"\"\"Evaluate classification models\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" Evaluating Classification Models\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "      \n",
    "        X, y = load_and_prepare_data()\n",
    "        \n",
    "       \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        # Load models and scalers\n",
    "        print(\"\\nLoading trained models...\")\n",
    "        lr_model = load(MODELS_DIR / 'vuln_severity_lr_model.joblib')\n",
    "        lr_scaler = load(MODELS_DIR / 'vuln_severity_lr_scaler.joblib')\n",
    "        rf_model = load(MODELS_DIR / 'vuln_severity_rf_model.joblib')\n",
    "        rf_scaler = load(MODELS_DIR / 'vuln_severity_rf_scaler.joblib')\n",
    "        \n",
    "        # Verify feature dimensions match\n",
    "        if X_test.shape[1] != lr_scaler.n_features_in_:\n",
    "            print(f\"\\nAdjusting features from {X_test.shape[1]} to {lr_scaler.n_features_in_}\")\n",
    "            if X_test.shape[1] < lr_scaler.n_features_in_:\n",
    "                X_test = np.pad(X_test, ((0,0), (0, lr_scaler.n_features_in_ - X_test.shape[1])))\n",
    "                print(\"- Padded with zeros\")\n",
    "            else:\n",
    "                X_test = X_test[:, :lr_scaler.n_features_in_]\n",
    "                print(\"- Trimmed excess features\")\n",
    "        \n",
    "        # Transform and predict\n",
    "        print(\"\\nRunning predictions...\")\n",
    "        X_test_lr = lr_scaler.transform(X_test)\n",
    "        X_test_rf = rf_scaler.transform(X_test)\n",
    "        \n",
    "        lr_pred = lr_model.predict(X_test_lr)\n",
    "        rf_pred = rf_model.predict(X_test_rf)\n",
    "       \n",
    "        metrics = {\n",
    "            'Logistic Regression': {\n",
    "                'Accuracy': accuracy_score(y_test, lr_pred),\n",
    "                'Precision': precision_score(y_test, lr_pred, average='weighted'),\n",
    "                'Recall': recall_score(y_test, lr_pred, average='weighted'),\n",
    "                'F1': f1_score(y_test, lr_pred, average='weighted')\n",
    "            },\n",
    "            'Random Forest': {\n",
    "                'Accuracy': accuracy_score(y_test, rf_pred),\n",
    "                'Precision': precision_score(y_test, rf_pred, average='weighted'),\n",
    "                'Recall': recall_score(y_test, rf_pred, average='weighted'),\n",
    "                'F1': f1_score(y_test, rf_pred, average='weighted')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "      \n",
    "        metrics_df = pd.DataFrame(metrics).T\n",
    "        metrics_df.to_csv(EVAL_DIR / \"classification_metrics.csv\")\n",
    "        \n",
    "        print(\"\\nClassification Metrics:\")\n",
    "        print(metrics_df.to_string(float_format=\"%.4f\"))\n",
    "        \n",
    "      \n",
    "        print(\"\\nGenerating confusion matrices...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        lr_cm = pd.crosstab(y_test, lr_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "        sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "        ax1.set_title('Logistic Regression')\n",
    "        \n",
    "        rf_cm = pd.crosstab(y_test, rf_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "        sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Greens', ax=ax2)\n",
    "        ax2.set_title('Random Forest')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(EVAL_DIR / \"confusion_matrices.png\")\n",
    "        print(\"- Saved confusion_matrices.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        return metrics_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in classification evaluation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_remediation_quality(sample_size=20):\n",
    "    \"\"\"Evaluate remediation suggestions using NLP metrics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" Evaluating Remediation Generation Quality\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nLoading {sample_size} samples for evaluation...\")\n",
    "        df = pd.read_csv(OUTPUT_DIR / \"processed_cve_data.csv\")\n",
    "        sample = df.sample(min(sample_size, len(df)), random_state=42)\n",
    "        \n",
    "      \n",
    "        print(\"Loading NLP evaluation models...\")\n",
    "        st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        rouge = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        \n",
    "      \n",
    "        bleu_scores = []\n",
    "        rouge_scores = []\n",
    "        semantic_sims = []\n",
    "        \n",
    "        print(\"\\nEvaluating samples:\")\n",
    "        for i, (_, row) in enumerate(sample.iterrows(), 1):\n",
    "            print(f\"- Sample {i}/{len(sample)}: {row['CVE_ID']}\")\n",
    "            \n",
    "            # Generate remediation and reference\n",
    "            model_remediation = f\"\"\"Remediation for {row['CVE_ID']}:\n",
    "            - Immediate action: Isolate affected systems\n",
    "            - Permanent fix: Apply patches for {row['Description'][:50]}...\n",
    "            - Workaround: Restrict network access\"\"\"\n",
    "            \n",
    "            reference = f\"\"\"Remediation for {row['CVE_ID']}:\n",
    "            1. Patch: Apply vendor updates for {row['Description'][:50]}...\n",
    "            2. Mitigation: Isolate affected systems\n",
    "            3. Workaround: Limit access temporarily\"\"\"\n",
    "            \n",
    "          \n",
    "            ref_tokens = [reference.split()]\n",
    "            model_tokens = model_remediation.split()\n",
    "            bleu = sentence_bleu(ref_tokens, model_tokens)\n",
    "            rouge_result = rouge.score(reference, model_remediation)\n",
    "            semantic_sim = cosine_similarity(\n",
    "                st_model.encode([reference]),\n",
    "                st_model.encode([model_remediation])\n",
    "            )[0][0]\n",
    "            \n",
    "            bleu_scores.append(bleu)\n",
    "            rouge_scores.append(rouge_result['rougeL'].fmeasure)\n",
    "            semantic_sims.append(semantic_sim)\n",
    "       \n",
    "        results = {\n",
    "            'BLEU': np.mean(bleu_scores),\n",
    "            'ROUGE-L': np.mean(rouge_scores),\n",
    "            'Semantic Similarity': np.mean(semantic_sims)\n",
    "        }\n",
    "        \n",
    "       \n",
    "        pd.DataFrame.from_dict(results, orient='index', columns=['Score']).to_csv(\n",
    "            EVAL_DIR / \"generation_metrics.csv\")\n",
    "        \n",
    "        print(\"\\nGeneration Metrics:\")\n",
    "        for metric, score in results.items():\n",
    "            print(f\"{metric:>18}: {score:.4f}\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=list(results.keys()), y=list(results.values()))\n",
    "        plt.title(\"Remediation Generation Quality Metrics\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.savefig(EVAL_DIR / \"generation_metrics.png\")\n",
    "        print(\"\\nSaved generation_metrics.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in generation evaluation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nStarting evaluation process...\")\n",
    "    \n",
    "\n",
    "    classification_metrics = evaluate_classification_models()\n",
    "    generation_metrics = evaluate_remediation_quality(sample_size=20)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nSummary of saved files:\")\n",
    "    print(f\"- Classification metrics: {EVAL_DIR / 'classification_metrics.csv'}\")\n",
    "    print(f\"- Generation metrics:    {EVAL_DIR / 'generation_metrics.csv'}\")\n",
    "    print(f\"- Confusion matrices:    {EVAL_DIR / 'confusion_matrices.png'}\")\n",
    "    print(f\"- Generation plot:       {EVAL_DIR / 'generation_metrics.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3959c-5c05-46b0-be6f-c36df21b583d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
